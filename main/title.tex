\thispagestyle{plain}
\begin{titlepage}
	\begin{center}
    	\Large
    	\textbf{Informed Consent and the Responsible Use of Big Data: The Ethical Implications of Facebook's "Emotional Contagion" Study}
    
    	\vspace{0.9cm}
    	\large
    	Gregory Davis
    
    	\vspace{0.4cm}
    	Computer Science
    
    	\vspace{0.4cm}
    	May 27, 2016
    
    	\vspace{0.4cm}
    	CPE 300
    
    	\vspace{1.8cm}
    	\textbf{Abstract}
        
    	\vspace{0.4cm}
       \end{center}
In January 2012, Facebook conducted an experimental study involving the spread of "emotional contagion" through social networks.  Users' posting behaviors were analyzed after their news feeds were filtered for removal of positive or negative content.  Facebook stated that no text was seen by the researchers and cited its Data Use Policy as sufficient informed consent for the experiment.  No explicit notification of participation or means of opting out was provided to the participants.  Was it ethical for Facebook to conduct this experiment on users who were unaware of their participation?
\par Critics argue that agreement to Facebook's Data Use Policy does not constitute informed consent and that users were not provided with the proper notification, debriefing, or opportunity to opt out of the study.  Others argue in defense of Facebook, suggesting that the risk to participants was insignificant enough to justify the exemption of explicit informed consent.  This paper examines the ethical implications of this experiment and concludes that Facebook's actions were in compliance with the Software Engineering Code of Ethics tenet 2.05, but were in violation of tenets 1.04 and 2.03.  Because the subjects were not made aware of the potential risks of the experiment, and users did not give permission for their data to be used in such an experiment, it was conducted unethically.
\end{titlepage}