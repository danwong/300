\subsection{Tenet 2.05: Privacy}
Tenet 2.05 of the SE Code of Ethics requires software engineers to "\uline{keep private} any \uline{confidential information} gained in their \uline{professional work}, where such confidentiality is consistent with the \uline{public interest} and consistent with the law" \cite{code}.

\subsubsection{Definitions}
\subsubsubsection{Keeping Private}
In the context of digital data, privacy "deals with the ability an ... individual has to determine what data in a computer system can be shared with third parties" \cite{define-information-privacy}.  More generally, privacy is "the state or condition of being free from being observed or disturbed by other people" \cite{define-privacy}.  These definitions suggest that to "keep private" is to "maintain freedom from observation by other people".

\subsubsubsection{Confidential Information}
Something that is "confidential" can also be considered "secret or private" \cite{define-confidential}.  Given the above definition of privacy, "confidential information" means information of which access to third parties is determined by the owner of the information.  Because data is information \cite{define-data}, and data is the relevant information in social media, "confidential information" means "data that is intended to be accessed only with permission of the owner".  As discussed in Section 6.2.1.1, the relevant data is a user's social media posts, and the owner is the user who generated that data.  Because Facebook's privacy settings provide users with the opportunity to decide who has permission to see their posts \cite{privacy-settings}, "data that is intended to be accessed only with the permission of the owner" includes social media posts.  Therefore, "confidential information" includes "social media posts".

\subsubsubsection{Professional Work}
Something that is "professional" "relat[es] to a job that requires special education, training, or skill" \cite{define-professional}.  Because "a software engineer is a licensed professional engineer" \cite{define-software-engineer}, "work done in a software engineering job" can be considered "professional work".  Because the Facebook researchers are software engineers (see Section 4), the "emotional contagion experiment" is the relevant professional work.

\subsubsubsection{Public Interest}
"Public interest", though a nebulous concept, is defined as "the welfare or well-being of the general public" \cite{define-public-interest}.  Without getting into too much detail, "public interest" is "the welfare of the general public".

\subsubsection{Domain Specific Rule}
In the domain of social media research, tenet 2.05 requires software engineers to "\uline{maintain freedom from observation by other people} any \uline{social media posts} gathered during \uline{the 'emotional contagion' experiment}, where such confidentiality is consistent with the \uline{welfare of the general public} and consistent with the law".

\subsubsection{Discussion}
\subsubsubsection{What Was Gathered During the Experiment?}
As mentioned in Section 6.2.3.1, social media posts were gathered for the 689,003 users who were involved in the experiment.  These posts include those made by the participant users, but also users they are connected to whose posts were filtered by the news feed algorithm.  This amounted to a total of roughly 3 million posts \cite{study}.

\subsubsubsection{Who Observed the Data?}
Also mentioned in Section 6.2.3.1, the "emotional contagion" paper states that posts were analyzed by the "Linguistic Inquiry and Word Count software (LIWC2007) word counting system" for the presence of positive or negative content, and that "no text was seen by the researchers" \cite{study}.  As mentioned in 6.1.3.2, James Grimmelmann agrees that "automated data processing is a meaningful way of avoiding privacy harms to research subjects" in spite of his criticism of the study \cite{laboratorium}.  Because the users' posts were analyzed by software and not seen by people, the researchers did "maintain freedom from observation by other people" with regards to social media posts.

\subsubsubsection{Welfare of the General Public and the Law}
If the researchers complied with the domain specific rule in maintaining the privacy of user data, are there any reasons why this was not consistent with the public good or the law? \par 
Experimental psychology is defined as "the branch of psychology dealing with the study of \textit{emotional}... activity... in humans... by means of experimental methods" \cite{define-experimental-psychology}.  Because the "emotional contagion" experiment studied emotional activity, it can be considered a psychological experiment.  The American Psychological Association has a code of ethics that addresses disclosure of confidential information.  The APA Ethical Standard 4.05 justifies the disclosure of confidential information when permitted or mandated by law, or for valid purposes such as protection of "the client/patient, psychologist, or others from harm" \cite{disclose-information}.  This standard also states that "the legal duty [of disclosure] is based upon a clinical assessment". \par
Would observation of the user data have protected anybody from harm? 
The users' posts were only analyzed for the purposes of finding positive or negative content, and the analysis was only used to tag posts as positive or negative for omission from the news feed.  Because of this, researchers could not have been able to determine whether posts demonstrated a risk of harm to anybody.  Furthermore, as the data was not assessed by the researchers, there could not have been any legal duty to disclose information.

\subsubsection{Conclusion}
The Facebook researchers who conducted the "emotional contagion" experiment gathered roughly 3 million social media posts for the purposes of the experiment.  The domain specific rule derived above from tenet 2.05 of the Software Engineering Code of Ethics mandates protection of this data from being observed by other people unless justified by the interests of the public good or the law.  Because the data was analyzed by software without being seen by people, it was successfully protected from observation.  Furthermore, because the posts were not assessed, no legitimate risk of harm could have been found to justify the disclosure of the data as consistent with the welfare of the general public or the law.  Therefore, the experiment was conducted in compliance with the domain specific rule, and tenet 2.05 from which it was derived.
\vspace{0.4cm}